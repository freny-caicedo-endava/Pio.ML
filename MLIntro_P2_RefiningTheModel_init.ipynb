{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLIntro_P2_RefiningTheModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Xx_MSuJWCbzo",
        "KhAlVRy5bURe",
        "W-yemSvTD2JF",
        "4ZFDf8CCTV4G"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freny-caicedo-endava/Pio.ML/blob/master/MLIntro_P2_RefiningTheModel_init.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jZ42_XB0Tup",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> ![answer](https://drive.google.com/uc?export=view&id=1yj7jPO0w4Ayq1OxkpflWOE-BBdMd_O4k)\n",
        "\n",
        "## Introduction to Machine Learning\n",
        "###PART TWO: Refining the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tOReNZ5GM2x",
        "colab_type": "text"
      },
      "source": [
        "# 1.  EVALUATION METRICS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6keUV-ShYsht",
        "colab_type": "text"
      },
      "source": [
        "**Confusion Matrix** is a performance measurement for machine learning classification problem, it is relatively simple to understand, but the related terminology can be confusing.\n",
        "\n",
        "> ![answer](https://drive.google.com/uc?export=view&id=1nbipIp7_oIEFQzkuf9o9F4bB_9W2L9rc)\n",
        "\n",
        "> ![answer](https://drive.google.com/uc?export=view&id=1Euhh_mSTMZwdyuanrFeDd4OeGgBRbFZn)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcrAB7_sQDcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_true = [1, 1, 0, 1, 0, 0, 1]\n",
        "y_pred = [1, 0, 0, 1, 0, 0, 1]\n",
        "\n",
        "# get confusion matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH1e9oAblw2I",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy:** Overall, how often is the classifier correct? When it predicts yes, how often is it correct?\n",
        "\n",
        "(TP+TN)/total \n",
        "\n",
        "**Precision:** When it predicts the positive result, how often is it correct?\n",
        "Fraction of positive predictions that are actually positive\n",
        "\n",
        "TP/(TP+FP)\n",
        "\n",
        "**Recall:** When it is actually the positive result, how often does it predict correctly?\n",
        "\n",
        "How much of actual positive data  was predicted to be positive.\n",
        "\n",
        "TP/(TP+FN)\n",
        "\n",
        "> ![answer](https://drive.google.com/uc?export=view&id=1jPebdA_bJKgq9vFuQhpA8sbF-v8LoMKT)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*When Is Precision more important?*\n",
        "\n",
        "Youtube recommendations, should it reccomend a product?\n",
        "\n",
        "FP: bad user experience!\n",
        "\n",
        "FN: not a big problem\n",
        "\n",
        "---\n",
        "\n",
        "*When Is Recall more important?*\n",
        "\n",
        "Lung Carcer Warning from x-ray\n",
        "\n",
        "FP: not a big problem\n",
        "\n",
        "FN: person loses chance to live!!!\n",
        "\n",
        "So, precision is important to avoid false positives.\n",
        "And recall is important to avoid false negatives.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**F1 Score:** is the harmonic average of the precision and recall.\n",
        "\n",
        "Harmonic mean is a kind of average where result is closer to the lower number, so F1 score is colest to the smallest between Precision and Recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hPptXkO820-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statistics as s\n",
        "\n",
        "values = [0.1, 0.8]\n",
        "\n",
        "# get harmonic mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGT6LZkA9jmU",
        "colab_type": "text"
      },
      "source": [
        "Note that F1 score gives equal importance to precision and recall.\n",
        "\n",
        "**F-Beta score:** is the weighted harmonic mean of precision and recall.\n",
        "\n",
        "The beta parameter determines the weight of recall in the combined score. \n",
        "\n",
        "*   *beta < 1* lends more weight to precision\n",
        "*   *beta > 1* favors recall\n",
        "*   *beta = 1* is just harmonic mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIcpsMW2hb7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
        "\n",
        "y_true = [1, 1, 0, 1, 0, 0, 1]\n",
        "y_pred = [1, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "# get and print accuracy, precision and recall\n",
        "\n",
        "# print harmonic mean and fbeta score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx_MSuJWCbzo",
        "colab_type": "text"
      },
      "source": [
        "# 2.  DETECTING ERRORS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEeZIahZC661",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 TYPES OF ERRORS "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnAhCxAcS05M",
        "colab_type": "text"
      },
      "source": [
        "**UNDERFITTING**\n",
        "\n",
        "Does not do well on the training set.\n",
        "Error due to bias.\n",
        "\n",
        "**OVERFITTING**\n",
        "\n",
        "Does well on the training set, but it tends to memorize it instead of learning the characteristics of it.\n",
        "Error due to variance.\n",
        "\n",
        "\n",
        "> ![answer](https://drive.google.com/uc?export=view&id=1psGrlora0dAitbFqKYnHWpAoKLrieW7V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8O5DqrjR9pL",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 CROSS VALIDATION\n",
        "\n",
        "Cross-validation is a statistical method used to estimate the skill of machine learning models.\n",
        "\n",
        "In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k âˆ’ 1 subsamples are used as training data. \n",
        "\n",
        "The cross-validation process is then repeated k times, with each of the k subsamples used exactly once as the validation data. The k results can then be averaged to produce a single estimation.\n",
        "\n",
        "Very useful when we have few data.\n",
        "\n",
        "> ![answer](https://drive.google.com/uc?export=view&id=1t_V8pJo000_ybbohxeuHqZlnrjz-RsPi)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhAlVRy5bURe",
        "colab_type": "text"
      },
      "source": [
        "# 3. DATA PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sskvJ8gYXVOp",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Handling Null Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzM6ZiC2e5Gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "csv_data = \\\n",
        "'''\n",
        "A,B,C,D\n",
        "1.0,2.0,3.0,4.0\n",
        "5.0,6.0,,8.0\n",
        "9.0,10.0,11.0,\n",
        "'''\n",
        "\n",
        "df = pd.read_csv(StringIO(csv_data))\n",
        "\n",
        "# preview data\n",
        "\n",
        "# show null positions\n",
        "\n",
        "# show nulls by column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKi9oiiSIx2_",
        "colab_type": "text"
      },
      "source": [
        "**How to fix it?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fPkid-nJC9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "# create Inputer instance\n",
        "\n",
        "# get rid of nulls on affected columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryzq34mPykld",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Standardization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YsKTl9fJ92b",
        "colab_type": "text"
      },
      "source": [
        "In Standardization we transform our values such that the mean of the values is 0 and the standard deviation is 1.\n",
        "\n",
        "![answer](https://drive.google.com/uc?export=view&id=1lNdkOnerB69nZ5IpgeKDY8Ci-63-O9Du)\n",
        "\n",
        "![answer](https://drive.google.com/uc?export=view&id=1uw9iuGjtipnNYZ7Rctha2s39KDnjh2Ys)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apdoVkGONKC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "csv_data = \\\n",
        "'''\n",
        "Country,Age,Salary\n",
        "Colombia,44.0,72000.0\n",
        "Spain,27.0,48000.0\n",
        "Germany,30.0,54000.0\n",
        "Colombia,38.0,61000.0\n",
        "Germany,70.0,63000.0\n",
        "'''\n",
        "\n",
        "df = pd.read_csv(StringIO(csv_data))\n",
        "\n",
        "# print data and histogram for Salary column\n",
        "\n",
        "# standarize Age and Salary columns\n",
        "\n",
        "# print new data and histogram for Salary column\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvj73CJ-XeRI",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Handling Categorical Variables\n",
        "\n",
        "Categorical variables are basically the variables that are discrete and not continuous, they are further divided into 2 types and we need to preprocess them differently.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyanMYdtzA1l",
        "colab_type": "text"
      },
      "source": [
        "### 3.3.1 ORDINAL\n",
        "\n",
        "Can be ordered, e.g. â€Šsize of a T-shirt, we can say that M<L<XL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsM1rS6_gpPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cat = pd.DataFrame(data = \n",
        "                     [['green','M'],\n",
        "                      ['blue','L'],\n",
        "                      ['green','S'],\n",
        "                      ['white','M']])\n",
        "df_cat.columns = ['color','size']\n",
        "\n",
        "df_cat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1WZ9PnInwlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map size column values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z180TCzwzHa1",
        "colab_type": "text"
      },
      "source": [
        "### 3.3.2 NOMINAL\n",
        "\n",
        "Canâ€™t be ordered., e.g. color of a T-shirt., we canâ€™t say that Blue < Green."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_HjkBW3vDyJ",
        "colab_type": "text"
      },
      "source": [
        "**Label Encoder**\n",
        "\n",
        "Encode labels with value between 0 and n_classes-1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUUYWneXhB6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# encode color columns values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyP_Gu2Ih4H-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**One-Hot Encoding**\n",
        "\n",
        "This method creates *n* columns where *n* is the number of unique values that the nominal variable can take, for each encoded value only one column have value = 1 and the rest all will have value = 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDpPK21YnRV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "df_cat = pd.DataFrame(data = \n",
        "                      [['green'],\n",
        "                       ['blue'],\n",
        "                       ['green'],\n",
        "                       ['white']])\n",
        "df_cat.columns = ['color']\n",
        "\n",
        "# print data\n",
        "\n",
        "# reshape and encode color values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-yemSvTD2JF",
        "colab_type": "text"
      },
      "source": [
        "# 4. TUNNING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0dbrMa3znVv",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 LOSS FUNCTION\n",
        "\n",
        "Itâ€™s a method of evaluating how well specific algorithm models the given data. If predictions deviates too much from actual results, the result will output a large number. \n",
        "\n",
        "A basic loss function will simply measure the absolute difference between our prediction and the actual value and average it out across the whole dataset.\n",
        "\n",
        "In mathematical notation, it might look something like abs(y_predicted â€“ y) \n",
        "\n",
        "\n",
        "![answer](https://drive.google.com/uc?export=view&id=1-nM2-cT6I0KMlzQLT3PSmxBTu97IcQPb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-g9QEZMwtut",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 HYPERPARAMETERS\n",
        "\n",
        "In machine learning, a hyperparameter is a parameter whose value is set before the learning process begins, they are not derived via training.\n",
        "\n",
        "Hyperparameter optimization finds values that yields an optimal model which minimizes a loss function on given test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgdhUvytwzrN",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 BENCHMARK MODEL\n",
        "\n",
        "Benchmarking is the process of comparing your result to existing methods. \n",
        "\n",
        "You may compare to published results from another paper, for example. Or you might compare to a very simple model (a simple regression, K Nearest Neighbors). \n",
        "\n",
        "If the field is well studied, you should probably benchmark against the current published state of the art (and possibly against human performance when relevant).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZFDf8CCTV4G",
        "colab_type": "text"
      },
      "source": [
        "# 5. REFINING PREVIOUS MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0wLhdcmrFZz",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW-YQpjHUK97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_url = 'https://raw.githubusercontent.com/freny-caicedo-endava/Pio.ML/master/census.csv'\n",
        "\n",
        "# load to Pandas Dataframe and preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYIaYkSGW3Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# enconde income values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8vc1zwlpNZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove target column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op0M82ybWVbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "numeric_cols = ['age', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
        "\n",
        "# handle Null values and Standarize data in numerical columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsE_UgJOxWRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "categorical_cols = ['workclass', 'education_level', 'marital_status',\n",
        "                    'occupation', 'relationship', 'race', 'sex', \n",
        "                    'native_country']\n",
        "\n",
        "# Handle Null values in categorical cols\n",
        "    \n",
        "\n",
        "# Map education level values as Categorical Ordinal\n",
        "\n",
        "eduLevel_mapping = {\n",
        "    ' Preschool': 0,\n",
        "    ' Some-college':1,\n",
        "    ' 1st-4th':2,\n",
        "    ' 5th-6th':3,\n",
        "    ' 7th-8th':4,\n",
        "    ' 9th':5,\n",
        "    ' 10th':6,\n",
        "    ' 11th':7,\n",
        "    ' 12th':8,\n",
        "    ' HS-grad':9,\n",
        "    ' Bachelors':10,\n",
        "    ' Masters':11,\n",
        "    ' Prof-school':12,\n",
        "    ' Assoc-acdm':13,\n",
        "    ' Assoc-voc':14,\n",
        "    ' Doctorate':15\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slnO1e7k5sZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Apply OneHot encoder to Categorical Nominal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI1H-IUIEdV4",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 TUNNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhRjmU9Z_kHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# get best parameters for Decision Tree algorithm\n",
        "\n",
        "param_grid = { \n",
        "    'max_depth': [15, 32, 64],\n",
        "    'min_samples_split': [0.000001, 0.00001, 0.0001],\n",
        "    'min_samples_leaf' : [0.0001, 0.001, 0.01]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1kiK7tqtCXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# apply found optimal values\n",
        "\n",
        "\n",
        "# measure accuracy again\n",
        "#\n",
        "# Benchmark model = Decision Tress trained in previous workshop\n",
        "# Benchmark model Accuracy: 0.82 (+/- 0.00812)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}